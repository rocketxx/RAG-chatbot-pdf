# ğŸ“„ Chatbot PDF con LangChain, Chroma e Ollama  

Questo Ã¨ un chatbot basato su **LangChain**, **ChromaDB** e **Ollama**, che permette di caricare un file **PDF**, indicizzarlo e interrogarlo con il modello **LLaMA 3.2**.  
L'app utilizza **Streamlit** per l'interfaccia utente e puÃ² essere eseguita in un ambiente **Docker** con **Docker Compose**.

## ğŸš€ FunzionalitÃ   
- ğŸ“‚ **Caricamento di file PDF**  
- ğŸ” **Indicizzazione del contenuto con ChromaDB**  
- ğŸ’¬ **Interrogazione del PDF tramite LLaMA 3.2 di Ollama**  
- ğŸŒ **Interfaccia utente semplice con Streamlit**  

## ğŸ› ï¸ Requisiti  
Assicurati di avere installati:  
- **Python 3.9+**  
- **Docker e Docker Compose**  

## ğŸ“¦ Installazione  

### 1ï¸âƒ£ Clona il repository  
```sh
git clone https://github.com/tuo-utente/chatbot-pdf.git
cd chatbot-pdf
```

### 2ï¸âƒ£ Installa le dipendenze  
Se vuoi eseguire l'app senza Docker:  
```sh
pip install -r requirements.txt
```

### 3ï¸âƒ£ Avvia l'app con Docker Compose  
```sh
docker compose up --build
```
L'app sarÃ  accessibile su **http://localhost:8501**.

## ğŸ“œ Dipendenze  
Il progetto utilizza le seguenti librerie:  

```txt
streamlit
langchain
langchain-community
chromadb
pypdf
sentence-transformers
```

## âš™ï¸ Struttura del Progetto  
```
ğŸ“‚ chatbot-pdf/
â”‚-- ğŸ“„ Dockerfile
â”‚-- ğŸ“„ docker-compose.yml
â”‚-- ğŸ“„ requirements.txt
â”‚-- ğŸ“„ app.py
â”‚-- ğŸ“„ README.md
```

## ğŸ“ Come Funziona  

1ï¸âƒ£ **Caricamento del PDF**  
L'utente carica un file **PDF** tramite l'interfaccia **Streamlit**.  

2ï¸âƒ£ **Indicizzazione del contenuto**  
Il documento viene suddiviso in pagine e trasformato in vettori con il modello `all-MiniLM-L6-v2`.  

3ï¸âƒ£ **Interrogazione del PDF**  
L'utente inserisce una domanda e il chatbot risponde in base al contenuto del documento.  

## ğŸ› ï¸ Configurazione Docker  

### ğŸ“„ `docker-compose.yml`
```yaml
version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - '11434:11434'
    volumes:
      - ollama_data:/root/.ollama

  chatbot:
    build: .
    ports:
      - '8501:8501'
    volumes:
      - .:/app
    environment:
      - OLLAMA_HOST=ollama:11434
    depends_on:
      - ollama

volumes:
  ollama_data:
```

### ğŸ“„ `Dockerfile`
```dockerfile
FROM python:3.9

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

## ğŸ† Contributi  
Se vuoi migliorare il progetto, sentiti libero di aprire una **pull request** o segnalare problemi nella sezione **Issues**.  

## ğŸ“œ Licenza  
Questo progetto Ã¨ distribuito sotto licenza **MIT**.  

---

ğŸ“Œ **Creato con â¤ï¸ da [Il Tuo Nome](https://github.com/tuo-utente)**
